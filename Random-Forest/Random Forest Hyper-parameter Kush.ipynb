{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBT\n",
    "from sklearn.decomposition import PCA\n",
    "%matplotlib inline\n",
    "\n",
    "#from sklearn.preprocessing import CategoricalEncoder\n",
    "#CategoricalEncoder is part of sklearn's developer version, which you can't just update with conda. If you have issues\n",
    "#getting this version, try a hard code implementation of the library here - https://pastebin.com/qs1es9XE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_column(df, col, thresh=200):\n",
    "    if df[col].nunique() > thresh:\n",
    "        df_frequency = df[[col, 'c_cnt']].groupby(col).agg('count').sort_values('c_cnt',ascending=False)\n",
    "        cat = [sorted(df_frequency[0:thresh].index.values)]\n",
    "        dict2 = {}\n",
    "        for i, item in enumerate(cat[0]):\n",
    "            dict2[item] = i\n",
    "        #enc = CategoricalEncoder(categories=[sorted(df_frequency[0:thresh].index.values)],handle_unknown='ignore')\n",
    "    else:\n",
    "        dict2 = {}\n",
    "        i = 0\n",
    "        for item in df[col].values:\n",
    "            if item not in dict2:\n",
    "                dict2[item] = i\n",
    "                i+=1\n",
    "        #enc = CategoricalEncoder(categories='auto',handle_unknown='ignore')\n",
    "    return [[1 if j == i else 0 for j in dict2] for i in df[col].values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset appears to consist of two types of samples - bid samples, and ad samples. Since we are only trying to predict clicks on the ad, AKA \"c_cnt\", which only exists in ad samples, we will only be working with those data. Let's first parse the data and get what we need.\n",
    "\n",
    "Parsing data from 12 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hours = []\n",
    "for i in range(12): \n",
    "    hours.append(pd.read_json(\"hour\" + str(i) + \".json\", lines=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a copy of the table as backup (in case original data gets corrupted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table = pd.concat(hours)\n",
    "safe_table = table.copy()\n",
    "df = table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to do some data cleaning. From some initial exploratory analysis, we can see that that we have 5 features with only 16 non-nan values, with a few other features having a similarly low level of non-nan values. To simplify things, we choose to drop all features with less than some threshhold of non-nan values. Also, as we are trying to predict c_cnt, samples where c_cnt is NaN are useless, so we throw those away as well. \n",
    "\n",
    "After this, we see that less than 10% of our remaining samples contains any NaN values, so we just drop those samples as we don't lose that much information from them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ad_network_id            1883983\n",
      "ad_type                  1883983\n",
      "advertiser_id            1883983\n",
      "bid_requests             1883983\n",
      "bid_responses            1883983\n",
      "c_cnt                    1468618\n",
      "c_timestamp                  914\n",
      "c_txn_fee                    914\n",
      "c_txn_rate                   914\n",
      "campaign_id              1883983\n",
      "campaign_type            1883983\n",
      "cr_cnt                   1883983\n",
      "creative_id              1883983\n",
      "exp_mode                  427894\n",
      "f_cnt                    1468618\n",
      "geo_continent_code       1883983\n",
      "geo_country_code2        1883983\n",
      "geo_dma_code             1883983\n",
      "geo_region_name          1838935\n",
      "geo_timezone             1857314\n",
      "i_cnt                    1468618\n",
      "i_timestamp              1467727\n",
      "pub_network_id           1883983\n",
      "r_cnt                    1883983\n",
      "r_num_ads_requested      1883983\n",
      "r_num_ads_returned       1883983\n",
      "r_num_ads_third_party    1883983\n",
      "r_timestamp              1883983\n",
      "rate_metric              1883983\n",
      "session_id               1883983\n",
      "site_id                  1883983\n",
      "token                    1883983\n",
      "txn_fee                      914\n",
      "txn_rate                     914\n",
      "ua_device                1883983\n",
      "ua_device_type           1877769\n",
      "ua_name                  1883983\n",
      "ua_os_name               1883983\n",
      "vi_cnt                   1468618\n",
      "vi_timestamp              200809\n",
      "vv_cnt                   1468618\n",
      "zone_id                  1883983\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#how many non-nan values do we have?\n",
    "print(df.count())\n",
    "n = len(df)\n",
    "\n",
    "#filter rows with c_cnt as NaN\n",
    "df = df[np.isfinite(df['c_cnt'])]\n",
    "\n",
    "#filter threshhold\n",
    "df = df.dropna(thresh=int(0.5*n), axis=1)\n",
    "#drop all samples with NaN values\n",
    "df = df.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have some more preprocessing to do, so we wrote some simple functions for preprocessing. The most important thing we do here is that since most of our features are categorical, we must encode them with one-hot-encoding, which essentially turns one feature into n different features, one for each type of class in the original features. For example, if we had a feature for \"hair color\", we would map it to a higher dimensional feature space consisting of \"is the hair white\", \"is the hair black\", \"is the hair brown\", etc. Only one of these features would be a 1, and the rest would be 0.\n",
    "\n",
    "Normally, each feature would be mapped to n features, with n being the number of unique classes that feature contains. For our data, however, some features will have thousands, even millions of unique classes, which would result is an omega-sparse dataset. To account for this, we set a threshhold at 200, such that n will never be greater than 201. We still keep track of the 200 most frequent classes, however, the rest will be bunched into a single class. The motivation for this is that for the more frequent classes, we have enough data that our ML models will be able to extract some information, but for the less frequent classes, there is too little data for accurate analysis, so we group them as one class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Turns a timestamp into which minute the time was at - used as a categorical feature.\n",
    "def timestamp_to_min(timestamp, is_hour=True):\n",
    "    if is_hour:\n",
    "        return timestamp.split(':')[0][-2:]\n",
    "    else: \n",
    "        return timestamp.split(':')[1]\n",
    "\n",
    "#plots frequency of a feature's different classes, useful for exploratory analysis\n",
    "def plot_freq(col_name, df):\n",
    "    df_frequency = df.groupby(col_name).agg('count').sort_values('ad_type',ascending=False)\n",
    "    plt.plot([i for i in range(len(df_frequency.values))], [np.log(i[2]) for i in df_frequency.values])\n",
    "    plt.show()\n",
    "\n",
    "#if a feature only has one unique value, it tells us nothing, so we drop it.\n",
    "def remove_only_ones(df):\n",
    "    for col in df.columns:\n",
    "        if len(df[col].unique()) == 1:\n",
    "            df.drop(col, inplace=True,axis=1)\n",
    "\n",
    "#just prints how many unique values are in each feature\n",
    "def print_column_counts(df):    \n",
    "    for i in df:\n",
    "        print(i, df[i].nunique())\n",
    "\n",
    "#We do some final cleaning, changing all non-numerical features into strings for later.\n",
    "def preprocess(df):    \n",
    "    for i in df:\n",
    "        if i[-1] != 't' or i[-2] != 'n' or i[-3] != 'c':\n",
    "            df[i] = df[i].astype('str')\n",
    "    remove_only_ones(df)\n",
    "    if 'site_id' in df.columns:\n",
    "        df.drop('site_id',inplace=True,axis=1)\n",
    "    df['i_timestamp'] = df['i_timestamp'].apply(timestamp_to_min)\n",
    "    df['r_timestamp'] = df['r_timestamp'].apply(timestamp_to_min)\n",
    "    \n",
    "\n",
    "\n",
    "#final preprocessing\n",
    "preprocess(df)\n",
    "#this set contains our numerical column names\n",
    "numerical_features = set(['c_cnt', 'i_cnt', 'r_cnt', 'vi_cnt'])\n",
    "#we create a copy so that X will not include 'c_cnt'\n",
    "df2 = df.copy()\n",
    "df2.drop('c_cnt',inplace=True,axis=1)\n",
    "#u,s,v = np.linalg.svd(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#given a categorical column, we apply our earlier strategy of one-hot-encoding with maximum thresh=200\n",
    "def transform_column(df, col, thresh=200, return_labels=False):\n",
    "    print(col)\n",
    "    df_frequency = df[[col, 'c_cnt']].groupby(col).agg('count').sort_values('c_cnt',ascending=False)\n",
    "    if df[col].nunique() > thresh:\n",
    "        enc = CategoricalEncoder(categories=[sorted(df_frequency[0:thresh].index.values)],handle_unknown='ignore')\n",
    "        labels = df_frequency[0:thresh].index.values\n",
    "    else:\n",
    "        enc = CategoricalEncoder(categories=[sorted(df_frequency.index.values)],handle_unknown='ignore')\n",
    "        labels = df_frequency.index.values\n",
    "    labels = [str(col) + str(i) for i in labels]\n",
    "    if return_labels:\n",
    "        return labels\n",
    "    enc.fit(df[col].values.reshape(-1, 1))\n",
    "    return enc.transform(df[col].values.reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create our X and Y matrices - adjust threshhold values for 1HE here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_thresh = 20\n",
    "Y = df['c_cnt'].values\n",
    "X = np.hstack([transform_column(df, col, thresh=one_hot_thresh) if col not in numerical_features else df[col].values.reshape(-1,1)\n",
    "               for col in df2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we split the data into 2 sets: training and testing to avoid overfitting of the model. This is done before any subsampling to avoid contaminating the test set. The train set is now subsampled to increase ratio of clicks to nonclicks from 1:2000 to 1:3 which allows models to more accurately learn the click patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fix_class_imbalance_with_subsampling(tempX, tempY, pos_ratio=2):\n",
    "    tempY = tempY.reshape(-1,1)\n",
    "    ind_1, ind_0 = [], []\n",
    "    for i, y_h in enumerate(tempY):\n",
    "        if y_h: ind_1.append(i)\n",
    "        else: ind_0.append(i)\n",
    "    to_sample = np.random.permutation(pos_ratio*len(ind_1))\n",
    "    to_sample_0 = [ind_0[i] for i in to_sample]\n",
    "    X2 = np.vstack([tempX[ind_1],tempX[to_sample_0]])\n",
    "    Y2 = np.vstack([tempY[ind_1],tempY[to_sample_0]])\n",
    "    tempY = tempY.reshape(-1)\n",
    "    \n",
    "    new_ind = np.random.permutation(len(X2))\n",
    "    return X2[new_ind],Y2[new_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, Y, test_size=0.3)\n",
    "\n",
    "X_fix , Y_fix = fix_class_imbalance_with_subsampling(X_train, y_train, pos_ratio=3)\n",
    "Y_fix=Y_fix.ravel()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom training score for various paramters - Inverse of Euclidian Distance: Rewards both higher and less \"extreme\" values. Uses Precision of training as X and Recall as Y. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(y_pred , y_test):\n",
    "    test = confusion_matrix(y_test , y_pred)\n",
    "    prec = test[1][1] / (test[1][1] + test[0][1])\n",
    "    rec = test[1][1] / (test[1][1] + test[1][0])\n",
    "    print(\"Precision: \", prec)\n",
    "    print(\"Recall\" , rec)\n",
    "    return ((prec ** 0.5) * (rec ** 0.5))**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run PCA to condense the data to 80% of it's variance, but cut the featuers from 350 -> 30. This allows it to train faster later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 0.8)\n",
    "pca.fit(X_train)\n",
    "X_train_small = pca.transform(X_train)\n",
    "X_test_small = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run a search across all possible paramters for RF in order to find one that maximizes score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.00288352674781\n",
      "Recall 0.634241245136\n",
      "Precision:  0.0048107495369\n",
      "Recall 0.677042801556\n",
      "Precision:  0.00476293570037\n",
      "Recall 0.684824902724\n",
      "Precision:  0.00481413605405\n",
      "Recall 0.684824902724\n",
      "Precision:  0.00289504965681\n",
      "Recall 0.587548638132\n",
      "Precision:  0.00486558812796\n",
      "Recall 0.622568093385\n",
      "Precision:  0.00491421190082\n",
      "Recall 0.68093385214\n",
      "Precision:  0.00496485551713\n",
      "Recall 0.692607003891\n",
      "Precision:  0.00298049294141\n",
      "Recall 0.649805447471\n",
      "Precision:  0.00533796974134\n",
      "Recall 0.68093385214\n",
      "Precision:  0.00483965176759\n",
      "Recall 0.677042801556\n",
      "Precision:  0.00473738978038\n",
      "Recall 0.673151750973\n",
      "Precision:  0.0024479252707\n",
      "Recall 0.634241245136\n",
      "Precision:  0.00506781934715\n",
      "Recall 0.661478599222\n",
      "Precision:  0.00472736164317\n",
      "Recall 0.677042801556\n",
      "Precision:  0.00475000686417\n",
      "Recall 0.673151750973\n",
      "Precision:  0.00303744997141\n",
      "Recall 0.661478599222\n",
      "Precision:  0.00464252553389\n",
      "Recall 0.642023346304\n",
      "Precision:  0.00481277766025\n",
      "Recall 0.708171206226\n",
      "Precision:  0.0047412300562\n",
      "Recall 0.692607003891\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "weight = {0:1 , 1:1}\n",
    "\n",
    "scores = []\n",
    "\n",
    "for max_feat in [\"auto\" , \"log2\",  10 , 30 , 50]:\n",
    "    n_s = []\n",
    "    for n_est in [1 , 10 ,50 ,100]:\n",
    "        mdl = RFC(max_features = max_feat, n_estimators = n_est , class_weight = weight)\n",
    "        mdl.fit(X_fix , Y_fix)\n",
    "        y_pred = mdl.predict(X_test)\n",
    "        fs = f1_score(y_test,y_pred)\n",
    "        #print(fs)\n",
    "        n_s.append(fs)\n",
    "        score(y_pred , y_test)\n",
    "       # n_s.append(score(y_pred , y_test))\n",
    "    scores.append(n_s)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the number of estimators (1,10 ,50 ,100) on the x-axis vs number of maximum number of features in a given tree (sqrt , lg2 , 10 , 30 , 50) : y-axis, in a heat map format to see which features provide highest accuracy. Use F1 metric to score models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x24d2101cb38>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD8CAYAAABekO4JAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24c802f97b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like lg2 features did the most consistently and 50 estimators did the best. So use these for next grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes for reading confusion matrix\n",
    "\n",
    "[0][0] correct non-clicked\n",
    "[1][0] - Incorrect - ACTUALLY CLICK\n",
    "[0][1] - Inccroect  - ACTUALLY NONCLICK\n",
    "[1][1] - correct click\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do another grid search on Weighting and Max_depth. Trying to see if weighting the positive class will increase precision from last classifcation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  nan\n",
      "Recall 0.0\n",
      "Precision:  0.0170212765957\n",
      "Recall 0.0155642023346\n",
      "Precision:  0.00499873627454\n",
      "Recall 0.692607003891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  nan\n",
      "Recall 0.0\n",
      "Precision:  0.0078125\n",
      "Recall 0.105058365759\n",
      "Precision:  0.0048440554092\n",
      "Recall 0.665369649805\n",
      "Precision:  0.0136612021858\n",
      "Recall 0.0194552529183\n",
      "Precision:  0.00740667588386\n",
      "Recall 0.583657587549\n",
      "Precision:  0.00485080940831\n",
      "Recall 0.669260700389\n",
      "Precision:  0.000596870725233\n",
      "Recall 1.0\n",
      "Precision:  0.00222275956996\n",
      "Recall 0.929961089494\n",
      "Precision:  0.00487977754757\n",
      "Recall 0.696498054475\n",
      "Precision:  0.000596870725233\n",
      "Recall 1.0\n",
      "Precision:  0.000604458409969\n",
      "Recall 1.0\n",
      "Precision:  0.00504574438592\n",
      "Recall 0.708171206226\n",
      "Precision:  0.000596870725233\n",
      "Recall 1.0\n",
      "Precision:  0.0006015917603\n",
      "Recall 1.0\n",
      "Precision:  0.00497582368155\n",
      "Recall 0.688715953307\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "weight = {0:1 , 1:1}\n",
    "\n",
    "scores = []\n",
    "\n",
    "for weights in [0.001 , 0.1, 1,10,100,1000]:\n",
    "    n_s = []\n",
    "    for max_depths  in [1 , 10 , 100]:\n",
    "        weight = {0:1 , 1:weights}\n",
    "        mdl = RFC(max_features = \"log2\", n_estimators = 50 , class_weight = weight , max_depth= max_depths)\n",
    "        mdl.fit(X_fix , Y_fix)\n",
    "        y_pred = mdl.predict(X_test)\n",
    "        fs = f1_score(y_test,y_pred)\n",
    "        #print(fs)\n",
    "        n_s.append(fs)\n",
    "        score(y_pred , y_test)\n",
    "       # n_s.append(score(y_pred , y_test))\n",
    "    scores.append(n_s)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heat map with weighting for positive class on y  [0.001 , 0.1, 1,10,100,1000] and max depth on X [1 , 10 , 100]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x24d8e8f4278>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD8CAYAAABekO4JAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24d8e8f1630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best performace currently: max_features = \"log2\", n_estimators = 50 , class_weight: 0:1 , 1:0.001 , max_depth= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.00721175516091\n",
      "Recall 0.311284046693\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0022449043302450707"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl = RFC(max_features = \"log2\", n_estimators = 50 , class_weight = {0:1 , 1:1.5} , max_depth= 1)\n",
    "mdl.fit(X_fix , Y_fix)\n",
    "y_pred = mdl.predict(X_test)\n",
    "score(y_pred , y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunetly still has very poor performance on all paramters - need to work on feature selection to improve model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBT\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "import itertools\n",
    "import pickle\n",
    "import datetime\n",
    "import pytz\n",
    "from pytz import timezone\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.base import clone\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "OHE_PATH = \"data/ohe_labels.pkl\"\n",
    "#from sklearn.preprocessing import CategoricalEncoder\n",
    "#CategoricalEncoder is part of sklearn's developer version, which you can't just update with conda. If you have issues\n",
    "#getting this version, try a hard code implementation of the library here - https://pastebin.com/qs1es9XE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load in data for train and test\n",
    "\n",
    "df_store = pd.HDFStore('data/day2_negatives_processed.h5')\n",
    "neg = df_store['df']\n",
    "neg = neg[:50000]\n",
    "df_store = pd.HDFStore('data/day2_positives_processed.h5')\n",
    "pos = df_store['df']\n",
    "pos = pos[:50000]\n",
    "df = pd.concat([neg,pos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_removed = df.drop( [ \"i_cnt\", \"vi_cnt\", \"r_num_ads_returned\", \"i_flag_cnt\", \"vi_flag_cnt\"] , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_store = pd.HDFStore('data/combined_day1_processed.h5')\n",
    "test = df_store['df']\n",
    "test = test[:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this is the helper function for preprocessing ohe labels - dont need to explicitly call this function\n",
    "def generate_ohe_labels(df, c, thresh=200, k_most_freq=False):\n",
    "    appears, oh_index = {}, {}\n",
    "    if c == 'keywords':\n",
    "        for val in df[c].values:\n",
    "            for word in val:\n",
    "                if word not in appears:\n",
    "                    appears[word] = 0\n",
    "                appears[word] += 1\n",
    "        if k_most_freq:\n",
    "            for v in sorted(appears)[0:thresh]:\n",
    "                oh_index[v] = len(oh_index)\n",
    "        else:\n",
    "            for v in [k for k in appears.keys()]:\n",
    "                if appears[v] < thresh:\n",
    "                    del appears[v]\n",
    "            for v in sorted(appears):\n",
    "                oh_index[v] = len(oh_index)\n",
    "    else:    \n",
    "        for val in df[c].values:\n",
    "            if val not in appears:\n",
    "                appears[val] = 0\n",
    "            appears[val] += 1\n",
    "        if k_most_freq:\n",
    "            for v in sorted(appears)[0:thresh]:\n",
    "                oh_index[v] = len(oh_index)\n",
    "        else:\n",
    "            for v in [k for k in appears.keys()]:\n",
    "                if appears[v] < thresh:\n",
    "                    del appears[v]\n",
    "            for v in sorted(appears):\n",
    "                oh_index[v] = len(oh_index)\n",
    "    return oh_index\n",
    "\n",
    "#generate OHE labels to be used for batch learning - run this FIRST\n",
    "def preprocess_ohe(df, thresh=200, path=OHE_PATH, k_most_freq=False):\n",
    "    #create and save our ohe labels\n",
    "    ohe_labels = {}\n",
    "    for c in df:\n",
    "        if c == 'c_cnt':\n",
    "            continue\n",
    "        else:\n",
    "            ohe_labels[c] = generate_ohe_labels(df, c, thresh, k_most_freq=k_most_freq)\n",
    "\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(ohe_labels, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "    return ohe_labels\n",
    "        \n",
    "#generates a small X and Y matrix by sampling from both negative and positive dataframes\n",
    "def generate_batch(df_pos, df_neg, batch_size, path=OHE_PATH, pos_ratio=1, ohe_labels=None):\n",
    "    #load our ohe labels\n",
    "    if ohe_labels == None:\n",
    "        with open(path, 'rb') as f:\n",
    "            ohe_labels = pickle.load(path)\n",
    "    \n",
    "    #pick which indices to use for our batch training\n",
    "    indices_touse_pos = np.random.permutation(len(df_pos))[0:batch_size]\n",
    "    indices_touse_neg = np.random.permutation(len(df_neg))[0:int(batch_size*pos_ratio)]\n",
    "    \n",
    "    #generate X and Y matrices\n",
    "    X, Y = [], []\n",
    "    for i in range(batch_size):\n",
    "        sample_x, sample_y = generate_one_sample(df_pos, ohe_labels)\n",
    "        X.append(sample_x)\n",
    "        Y.append(sample_y)\n",
    "    for i in range(int(batch_size*pos_ratio)):\n",
    "        sample_x, sample_y = generate_one_sample(df_neg, ohe_labels)\n",
    "        X.append(sample_x)\n",
    "        Y.append(sample_y)\n",
    "    \n",
    "    #shuffle X and Y matrices\n",
    "    shuffled_indices = np.random.permutation(len(X))\n",
    "    return [X[i] for i in shuffled_indices], [Y[i] for i in shuffled_indices]\n",
    "    \n",
    "#generates exactly one random sample from a dataframe using OHE. this is a helper function, shouldn't be explicitly called\n",
    "#if index is not -1, will not generate random index\n",
    "def generate_one_sample(df, ohe_labels, index=-1):\n",
    "    if index == -1:\n",
    "        index = np.random.randint(0,len(df))\n",
    "    X = [[0 if ohe_labels[c][df[c].values[index]] != j else 1 for j in range(len(ohe_labels[c]))]\n",
    "         if df[c].values[index] in ohe_labels[c] else [0 for j in range(len(ohe_labels[c]))]\n",
    "                  for c in ohe_labels if c != 'c_cnt' and c != 'keywords']\n",
    "    wordset = set([w for w in df['keywords'].values[index]])\n",
    "    X.append([1 if v in wordset else 0 for v in ohe_labels['keywords']])\n",
    "    X = np.array(X)\n",
    "    X = np.hstack(X)\n",
    "    return X, df['c_cnt'].values[index]\n",
    "\n",
    "#takes in the dataframe, returns an X and Y matrix \n",
    "def transform_df(df, ohe_labels):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(df)):\n",
    "        xmini, ymini = generate_one_sample(df, ohe_labels, index=i)\n",
    "        X.append(xmini)\n",
    "        Y.append(ymini)\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "\n",
    "k = 20\n",
    "#ohe_labels = preprocess_ohe(df, thresh=k, k_most_freq=True)\n",
    "#print(test.shape)\n",
    "X, Y = transform_df(df, ohe_labels)\n",
    "#X_test, Y_test = transform_df(test, ohe_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert data to DataFrames\n",
    "X = pd.DataFrame(X)\n",
    "Y = pd.DataFrame(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, Y, test_size=0.3)\n",
    "y_train = y_train[0].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Caclulates scoring of model on data \n",
    "def score(y_pred , y_test):\n",
    "    test = confusion_matrix(y_test , y_pred)\n",
    "    prec = test[1][1] / (test[1][1] + test[0][1])\n",
    "    rec = test[1][1] / (test[1][1] + test[1][0])\n",
    "    print(\"Precision: \", prec)\n",
    "    print(\"Recall\" , rec)\n",
    "    return f1_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.941537071691\n",
      "Recall 0.967380494597\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.95428384565075208"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train binary classifier models and get f1 score\n",
    "model = xgb.XGBClassifier(gamma = 5 , min_child_weight = 3, objective = 'binary:logistic')\n",
    "model.fit(X_train, y_train )\n",
    "y_pred = model.predict(X_test)\n",
    "score(y_pred ,y_test )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing extra columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ohe_labels = preprocess_ohe(df_removed, thresh=k, k_most_freq=True)\n",
    "#X_rem, Y_rem = transform_df(df_removed, ohe_labels)\n",
    "X_rem = pd.DataFrame(X_rem)\n",
    "Y_rem = pd.DataFrame(Y_rem)\n",
    "X_train_rem, X_test_rem, y_train_rem, y_test_rem = train_test_split( X_rem, Y_rem, test_size=0.3)\n",
    "y_train_rem = y_train_rem[0].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.919039318226\n",
      "Recall 0.952365023082\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.93540544092522016"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train binary classifier models and get f1 score\n",
    "\n",
    "model = xgb.XGBClassifier(gamma = 5 , min_child_weight = 3, objective = 'binary:logistic')\n",
    "model.fit(X_train_rem, y_train_rem )\n",
    "y_pred_rem = model.predict(X_test_rem)\n",
    "score(y_pred_rem ,y_test_rem )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## XGBoost for CTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create new Regressor model to \n",
    "model = xgb.XGBRegressor(objective = \"binary:logitraw\")\n",
    "model.fit(X_train ,y_train )\n",
    "y_pred_prob = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Normalize probabilities around average click rate and give a \"strength\" to how much from the mean the CTR can vary \n",
    "#(how much power you give to the model)\n",
    "def normalize(arr , strength):\n",
    "    avg = np.mean(arr)\n",
    "    stddev = np.std(arr)\n",
    "    arr = (arr-avg)/(stddev * 2 * strength)\n",
    "    arr = arr + (1/2234)\n",
    "    for i in range(len(arr)):\n",
    "        arr[i] = max(0 , arr[i])\n",
    "        arr[i] = min(1 , arr[i])      \n",
    "    return arr\n",
    "def evaluate(arr, corect):\n",
    "    return abs(sum(abs(corect - arr)) / len(arr)) * 100\n",
    "    \n",
    "new_pred = normalize(y_pred_prob , 2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00015335,  0.00013226,  0.00012721, ...,  0.00022853,\n",
       "        0.00041127,  0.00024896], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#New pred now has estimated click through rates for each ad.\n",
    "new_pred"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

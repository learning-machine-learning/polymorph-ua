{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "import itertools\n",
    "import datetime\n",
    "from pytz import timezone\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load preprocessed dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open our hdf files\n",
    "validate_store = pd.HDFStore('data/combined_day1_processed.h5')\n",
    "pos_store1 = pd.HDFStore('data/processed/day1_positives_processed.h5')\n",
    "neg_store1 = pd.HDFStore('data/processed/day1_negatives_processed.h5')\n",
    "pos_store2 = pd.HDFStore('data/processed/day2_positives_processed.h5')\n",
    "neg_store2 = pd.HDFStore('data/processed/day2_negatives_processed.h5')\n",
    "\n",
    "#Load out dataframes\n",
    "df_validate = validate_store['df']\n",
    "df_pos1 = pos_store1['df'] \n",
    "df_neg1 = neg_store1['df']\n",
    "df_pos2 = pos_store2['df'] \n",
    "df_neg2 = neg_store2['df']\n",
    "\n",
    "#Close our hdf files\n",
    "validate_store.close()\n",
    "pos_store1.close()\n",
    "neg_store1.close()\n",
    "pos_store2.close()\n",
    "neg_store2.close()\n",
    "\n",
    "#Shuffle dataframes\n",
    "df_validate = shuffle(df_validate)\n",
    "df_pos = shuffle(pd.concat([df_pos1, df_pos2]))\n",
    "df_neg = shuffle(pd.concat([df_neg1, df_neg2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SAMPLE_SIZE = min(df_pos.shape[0], df_neg.shape[0], 70000)\n",
    "SAMPLE_SIZE = 70000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 39)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.concat([df_pos.sample(int(0.5*SAMPLE_SIZE)), df_neg.sample(int(0.5*SAMPLE_SIZE))])\n",
    "df_train = shuffle(df_train)\n",
    "# df_test = shuffle(df_test.sample(int(0.3 * SAMPLE_SIZE)))\n",
    "df_test = shuffle(df_validate.sample(30000))\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['_host', 'ad_network_id', 'advertiser_id', 'c_cnt', 'c_flag_cnt',\n",
       "       'campaign_id', 'campaign_type', 'f_cnt', 'geo_city_name',\n",
       "       'geo_country_code3', 'geo_region_name', 'geo_timezone', 'i_cnt',\n",
       "       'i_flag_cnt', 'i_timestamp', 'pub_network_id', 'r_cnt',\n",
       "       'r_num_ads_requested', 'r_num_ads_returned', 'r_timestamp',\n",
       "       'rate_metric', 'referer', 'session_id', 'site_id', 'token', 'ua',\n",
       "       'ua_device', 'ua_device_type', 'ua_major', 'ua_minor', 'ua_os_name',\n",
       "       'url', 'user_agent', 'uuid', 'vi_cnt', 'vi_flag_cnt', 'url_domain',\n",
       "       'red_domain', 'keywords'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['_host', 'ad_network_id', 'advertiser_id', 'c_cnt', 'campaign_id',\n",
       "       'campaign_type', 'f_cnt', 'geo_city_name', 'geo_country_code3',\n",
       "       'geo_region_name', 'geo_timezone', 'pub_network_id', 'r_cnt',\n",
       "       'r_num_ads_requested', 'r_num_ads_returned', 'r_timestamp',\n",
       "       'rate_metric', 'referer', 'session_id', 'site_id', 'token', 'ua',\n",
       "       'ua_device', 'ua_device_type', 'ua_major', 'ua_minor', 'ua_os_name',\n",
       "       'url', 'user_agent', 'uuid', 'url_domain', 'red_domain', 'keywords'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_drop = ['c_flag_cnt', 'i_cnt', 'i_flag_cnt', 'i_timestamp', 'vi_cnt', 'vi_flag_cnt']\n",
    "df_train.drop(cols_to_drop, inplace=True, axis=1, errors='ignore')\n",
    "df_test.drop(cols_to_drop, inplace=True, axis=1, errors='ignore')\n",
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 33)\n",
      "(30000, 33)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_host</th>\n",
       "      <th>ad_network_id</th>\n",
       "      <th>advertiser_id</th>\n",
       "      <th>c_cnt</th>\n",
       "      <th>campaign_id</th>\n",
       "      <th>campaign_type</th>\n",
       "      <th>f_cnt</th>\n",
       "      <th>geo_city_name</th>\n",
       "      <th>geo_country_code3</th>\n",
       "      <th>geo_region_name</th>\n",
       "      <th>...</th>\n",
       "      <th>ua_device_type</th>\n",
       "      <th>ua_major</th>\n",
       "      <th>ua_minor</th>\n",
       "      <th>ua_os_name</th>\n",
       "      <th>url</th>\n",
       "      <th>user_agent</th>\n",
       "      <th>uuid</th>\n",
       "      <th>url_domain</th>\n",
       "      <th>red_domain</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>594384</th>\n",
       "      <td>an-prod-ralphie-frontline-kaiak.us-east-1</td>\n",
       "      <td>1341.0</td>\n",
       "      <td>3577.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18192.0</td>\n",
       "      <td>private</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Andover</td>\n",
       "      <td>USA</td>\n",
       "      <td>KS</td>\n",
       "      <td>...</td>\n",
       "      <td>PC</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16299.0</td>\n",
       "      <td>Windows 10</td>\n",
       "      <td>http://www.thegatewaypundit.com/2018/04/organi...</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...</td>\n",
       "      <td>05f8c845-16ed-4875-b273-be1c2a992c44</td>\n",
       "      <td>www.thegatewaypundit.com</td>\n",
       "      <td>www.thegatewaypundit.com</td>\n",
       "      <td>[organizers, illegal, migrant, caravan, headed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299448</th>\n",
       "      <td>an-prod-ralphie-frontline-fleck.eu-west-1</td>\n",
       "      <td>1173.0</td>\n",
       "      <td>3224.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14468.0</td>\n",
       "      <td>rtb</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Ulyanovsk</td>\n",
       "      <td>RUS</td>\n",
       "      <td>81</td>\n",
       "      <td>...</td>\n",
       "      <td>MOB</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>iOS</td>\n",
       "      <td></td>\n",
       "      <td>Viber/8.5.0.6 CFNetwork/894 Darwin/17.4.0</td>\n",
       "      <td>340EB9DB-CAA9-4F4D-9377-474D56F2CF23</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313653</th>\n",
       "      <td>an-prod-ralphie-frontline-scall.eu-west-1</td>\n",
       "      <td>734.0</td>\n",
       "      <td>3483.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24019.0</td>\n",
       "      <td>third-party</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Nizhniy Novgorod</td>\n",
       "      <td>RUS</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>PC</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Windows 10</td>\n",
       "      <td></td>\n",
       "      <td>Mozilla/5.0 (compatible; pycurl)</td>\n",
       "      <td>337ca0d2cbc6008f2086a88ab6fa5087ba706e1b</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442531</th>\n",
       "      <td>an-prod-ralphie-frontline-slain.eu-west-1</td>\n",
       "      <td>734.0</td>\n",
       "      <td>4315.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26882.0</td>\n",
       "      <td>outside</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Varazdin</td>\n",
       "      <td>HRV</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>MOB</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>iOS</td>\n",
       "      <td></td>\n",
       "      <td>Viber/8.6.0.65 CFNetwork/897.15 Darwin/17.5.0</td>\n",
       "      <td>0D2A73E6-F287-4A2B-8F07-46FB1B7ABEEE</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228048</th>\n",
       "      <td>an-prod-ralphie-frontline-egret.eu-west-1</td>\n",
       "      <td>734.0</td>\n",
       "      <td>4315.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26884.0</td>\n",
       "      <td>outside</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Tgls</td>\n",
       "      <td>HUN</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>MOB</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Android</td>\n",
       "      <td></td>\n",
       "      <td>Dalvik/2.1.0 (Linux; U; Android 8.0.0; TA-1024...</td>\n",
       "      <td>97438d7d-7923-440d-9af9-e7365e821667</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            _host  ad_network_id  \\\n",
       "594384  an-prod-ralphie-frontline-kaiak.us-east-1         1341.0   \n",
       "299448  an-prod-ralphie-frontline-fleck.eu-west-1         1173.0   \n",
       "313653  an-prod-ralphie-frontline-scall.eu-west-1          734.0   \n",
       "442531  an-prod-ralphie-frontline-slain.eu-west-1          734.0   \n",
       "228048  an-prod-ralphie-frontline-egret.eu-west-1          734.0   \n",
       "\n",
       "        advertiser_id  c_cnt  campaign_id campaign_type  f_cnt  \\\n",
       "594384         3577.0    0.0      18192.0       private    0.0   \n",
       "299448         3224.0    1.0      14468.0           rtb    0.0   \n",
       "313653         3483.0    0.0      24019.0   third-party    1.0   \n",
       "442531         4315.0    1.0      26882.0       outside    0.0   \n",
       "228048         4315.0    1.0      26884.0       outside    0.0   \n",
       "\n",
       "           geo_city_name geo_country_code3 geo_region_name  \\\n",
       "594384           Andover               USA              KS   \n",
       "299448         Ulyanovsk               RUS              81   \n",
       "313653  Nizhniy Novgorod               RUS              51   \n",
       "442531          Varazdin               HRV              16   \n",
       "228048              Tgls               HUN              10   \n",
       "\n",
       "                              ...                         ua_device_type  \\\n",
       "594384                        ...                                     PC   \n",
       "299448                        ...                                    MOB   \n",
       "313653                        ...                                     PC   \n",
       "442531                        ...                                    MOB   \n",
       "228048                        ...                                    MOB   \n",
       "\n",
       "        ua_major  ua_minor  ua_os_name  \\\n",
       "594384      16.0   16299.0  Windows 10   \n",
       "299448      11.0       2.0         iOS   \n",
       "313653      11.0       0.0  Windows 10   \n",
       "442531      11.0       3.0         iOS   \n",
       "228048      63.0       0.0     Android   \n",
       "\n",
       "                                                      url  \\\n",
       "594384  http://www.thegatewaypundit.com/2018/04/organi...   \n",
       "299448                                                      \n",
       "313653                                                      \n",
       "442531                                                      \n",
       "228048                                                      \n",
       "\n",
       "                                               user_agent  \\\n",
       "594384  Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...   \n",
       "299448          Viber/8.5.0.6 CFNetwork/894 Darwin/17.4.0   \n",
       "313653                   Mozilla/5.0 (compatible; pycurl)   \n",
       "442531      Viber/8.6.0.65 CFNetwork/897.15 Darwin/17.5.0   \n",
       "228048  Dalvik/2.1.0 (Linux; U; Android 8.0.0; TA-1024...   \n",
       "\n",
       "                                            uuid                url_domain  \\\n",
       "594384      05f8c845-16ed-4875-b273-be1c2a992c44  www.thegatewaypundit.com   \n",
       "299448      340EB9DB-CAA9-4F4D-9377-474D56F2CF23                             \n",
       "313653  337ca0d2cbc6008f2086a88ab6fa5087ba706e1b                             \n",
       "442531      0D2A73E6-F287-4A2B-8F07-46FB1B7ABEEE                             \n",
       "228048      97438d7d-7923-440d-9af9-e7365e821667                             \n",
       "\n",
       "                      red_domain  \\\n",
       "594384  www.thegatewaypundit.com   \n",
       "299448                             \n",
       "313653                             \n",
       "442531                             \n",
       "228048                             \n",
       "\n",
       "                                                 keywords  \n",
       "594384  [organizers, illegal, migrant, caravan, headed...  \n",
       "299448                                                 []  \n",
       "313653                                                 []  \n",
       "442531                                                 []  \n",
       "228048                                                 []  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "print(df_test.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot encoding of categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OHE_PATH = \"data/ohe_labels.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'If you wanted to do one hot encoding for k most frequent classes - use this code\\nohe_labels = preprocess_ohe(df_neg, thresh=k, k_most_freq=True)\\nX, Y = transform_df(df, ohe_labels)\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this is the helper function for preprocessing ohe labels - dont need to explicitly call this function\n",
    "def generate_ohe_labels(df, c, thresh=200, k_most_freq=False):\n",
    "    appears, oh_index = {}, {}\n",
    "    if c == 'keywords':\n",
    "        for val in df[c].values:\n",
    "            for word in val:\n",
    "                if word not in appears:\n",
    "                    appears[word] = 0\n",
    "                appears[word] += 1\n",
    "        if k_most_freq:\n",
    "            for v in sorted(appears)[0:thresh]:\n",
    "                oh_index[v] = len(oh_index)\n",
    "        else:\n",
    "            for v in [k for k in appears.keys()]:\n",
    "                if appears[v] < thresh:\n",
    "                    del appears[v]\n",
    "            for v in sorted(appears):\n",
    "                oh_index[v] = len(oh_index)\n",
    "    else:    \n",
    "        for val in df[c].values:\n",
    "            if val not in appears:\n",
    "                appears[val] = 0\n",
    "            appears[val] += 1\n",
    "        if k_most_freq:\n",
    "            for v in sorted(appears)[0:thresh]:\n",
    "                oh_index[v] = len(oh_index)\n",
    "        else:\n",
    "            for v in [k for k in appears.keys()]:\n",
    "                if appears[v] < thresh:\n",
    "                    del appears[v]\n",
    "            for v in sorted(appears):\n",
    "                oh_index[v] = len(oh_index)\n",
    "    return oh_index\n",
    "\n",
    "#generate OHE labels to be used for batch learning - run this FIRST\n",
    "def preprocess_ohe(df, thresh=200, path=OHE_PATH, k_most_freq=False):\n",
    "    #create and save our ohe labels\n",
    "    ohe_labels = {}\n",
    "    for c in df:\n",
    "        if c == 'c_cnt':\n",
    "            continue\n",
    "        else:\n",
    "            ohe_labels[c] = generate_ohe_labels(df, c, thresh, k_most_freq=k_most_freq)\n",
    "\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(ohe_labels, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "    return ohe_labels\n",
    "        \n",
    "#generates a small X and Y matrix by sampling from both negative and positive dataframes\n",
    "def generate_batch(df_pos, df_neg, batch_size, path=OHE_PATH, pos_ratio=1, ohe_labels=None):\n",
    "    #load our ohe labels\n",
    "    if ohe_labels == None:\n",
    "        with open(path, 'rb') as f:\n",
    "            ohe_labels = pickle.load(path)\n",
    "    \n",
    "    #pick which indices to use for our batch training\n",
    "    indices_touse_pos = np.random.permutation(len(df_pos))[0:batch_size]\n",
    "    indices_touse_neg = np.random.permutation(len(df_neg))[0:int(batch_size*pos_ratio)]\n",
    "    \n",
    "    #generate X and Y matrices\n",
    "    X, Y = [], []\n",
    "    for i in range(batch_size):\n",
    "        sample_x, sample_y = generate_one_sample(df_pos, ohe_labels)\n",
    "        X.append(sample_x)\n",
    "        Y.append(sample_y)\n",
    "    for i in range(int(batch_size*pos_ratio)):\n",
    "        sample_x, sample_y = generate_one_sample(df_neg, ohe_labels)\n",
    "        X.append(sample_x)\n",
    "        Y.append(sample_y)\n",
    "    \n",
    "    #shuffle X and Y matrices\n",
    "    shuffled_indices = np.random.permutation(len(X))\n",
    "    return [X[i] for i in shuffled_indices], [Y[i] for i in shuffled_indices]\n",
    "    \n",
    "#generates exactly one random sample from a dataframe using OHE. this is a helper function, shouldn't be explicitly called\n",
    "#if index is not -1, will not generate random index\n",
    "def generate_one_sample(df, ohe_labels, index=-1):\n",
    "    if index == -1:\n",
    "        index = np.random.randint(0,len(df))\n",
    "    X = [[0 if ohe_labels[c][df[c].values[index]] != j else 1 for j in range(len(ohe_labels[c]))]\n",
    "         if df[c].values[index] in ohe_labels[c] else [0 for j in range(len(ohe_labels[c]))]\n",
    "                  for c in ohe_labels if c != 'c_cnt' and c != 'keywords']\n",
    "    wordset = set([w for w in df['keywords'].values[index]])\n",
    "    X.append([1 if v in wordset else 0 for v in ohe_labels['keywords']])\n",
    "    X = np.array(X)\n",
    "    X = np.hstack(X)\n",
    "    return X, df['c_cnt'].values[index]\n",
    "\n",
    "#takes in the dataframe, returns an X and Y matrix \n",
    "def transform_df(df, ohe_labels):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(df)):\n",
    "        xmini, ymini = generate_one_sample(df, ohe_labels, index=i)\n",
    "        X.append(xmini)\n",
    "        Y.append(ymini)\n",
    "    return X, Y\n",
    "\n",
    "#generate ohe labels\n",
    "# ohe_labels = preprocess_ohe(df_neg, k_most_freq=False)\n",
    "#get validation set - take first 100,000 samples of both\n",
    "# df_validate = pd.concat([df_neg.head(100000), df_pos.head(100000)])\n",
    "# df_pos = df_pos.tail(len(df_pos)-100000)\n",
    "# df_neg = df_neg.tail(len(df_neg)-100000)\n",
    "\n",
    "\n",
    "'''If you wanted to do one hot encoding for k most frequent classes - use this code\n",
    "ohe_labels = preprocess_ohe(df_neg, thresh=k, k_most_freq=True)\n",
    "X, Y = transform_df(df, ohe_labels)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ohe labels done\n",
      "training set done\n",
      "test set done\n"
     ]
    }
   ],
   "source": [
    "ohe_labels = preprocess_ohe(df_train, thresh=20, k_most_freq=True)\n",
    "print(\"ohe labels done\")\n",
    "X_train, Y_train = transform_df(df_train, ohe_labels)\n",
    "print(\"training set done\")\n",
    "X_test, Y_test = transform_df(df_test, ohe_labels)\n",
    "print(\"test set done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, Y_train = pd.DataFrame(X_train), pd.DataFrame(Y_train)\n",
    "X_test, Y_test = pd.DataFrame(X_test), pd.DataFrame(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'confusion_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-45302d506b58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_neg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mohe_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mohe_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mtrain_cm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"iteration \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"with training score \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training confusion matrix:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'confusion_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def validate(model, df_validate):\n",
    "    sigmoid = lambda x: 1/(1+2.71828**(-1*x))\n",
    "    Y_test, Y_pred, Y_prob = [], [], []\n",
    "    #Separate the validation dataframe into batches of 100\n",
    "    for i in range(int(len(df_validate)/100)):\n",
    "        X, Y = [], []\n",
    "        for j in range(i*100,(i+1)*100):\n",
    "            miniX, miniY = generate_one_sample(df_validate, ohe_labels, index=j)\n",
    "            X.append(miniX)\n",
    "            Y.append(miniY)\n",
    "        Y_test.extend(Y)\n",
    "        Y_pred.extend(model.predict(X))\n",
    "        Y_prob.extend(model.decision_function(X))\n",
    "    #apply sigmoid activation to all decision function values\n",
    "    Y_prob = [sigmoid(i) for i in Y_prob]\n",
    "    #get class probabilities based on Y_predict and Y_prob\n",
    "    Y_prob = [[1-p, p] for i, p in enumerate(Y_prob)]\n",
    "    #get log loss\n",
    "    logloss = log_loss(Y_test, Y_prob)\n",
    "    test_cm = confusion_matrix(Y_test, Y_pred)\n",
    "    \n",
    "    return logloss, test_cm\n",
    "\n",
    "model = SGDClassifier(loss='log',penalty='l1',alpha=0.1)\n",
    "X, Y = generate_batch(df_pos, df_neg, 100, ohe_labels=ohe_labels)\n",
    "model.partial_fit(X, Y, classes=[0, 1])\n",
    "for i in range(10000):\n",
    "    X, Y = generate_batch(df_pos, df_neg, 100, ohe_labels=ohe_labels)\n",
    "    if i % 10 == 0 and i != 0:\n",
    "        train_cm = confusion_matrix(Y, model.predict(X))\n",
    "        print(\"iteration \", i, \"with training score \", model.score(X,Y))\n",
    "        print(\"Training confusion matrix:\")\n",
    "        print(train_cm)\n",
    "    if i % 10 == 0 and i != 0:\n",
    "        logloss, test_cm = validate(model, df_validate)\n",
    "        print(\"Log loss score: \", logloss)\n",
    "        print(\"Test confusion matrix:\")\n",
    "        print(test_cm)\n",
    "    model.partial_fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "We will be using f1 score to measure our models, which is a good performance measurement scalar for datasets\n",
    "where the negatives >> positives.\n",
    "'''\n",
    "def get_f1_score(test_cm):\n",
    "    true_neg  = test_cm[0][0]\n",
    "    false_pos = test_cm[0][1]\n",
    "    false_neg = test_cm[1][0]\n",
    "    true_pos  = test_cm[1][1]\n",
    "    precision = true_pos/(true_pos+false_pos)\n",
    "    recall = true_pos/(true_pos+false_neg)\n",
    "    if precision + recall == 0: return 0\n",
    "    score = 2*precision*recall/(precision+recall)\n",
    "    return score\n",
    "\n",
    "'''\n",
    "Returns (precision, recall)\n",
    "'''\n",
    "def cm_score(cm): \n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    return tp/(tp+fp), tp/(tp+fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest classifier to rank importance of numerical featuers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y = generate_batch(df_pos, df_neg, 1000, ohe_labels=ohe_labels)\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, Y_train = pd.DataFrame(X), pd.DataFrame(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-114526cf45fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimportances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimportances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mohe_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-32-114526cf45fe>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimportances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimportances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mohe_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "importances = rfc.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "print([list(ohe_labels.keys())[i] for i in indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_biased = shuffle(pd.concat([df_pos.sample(int(0.1*SAMPLE_SIZE)), df_neg.sample(int(0.9*SAMPLE_SIZE))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_biased, Y_biased = transform_df(df_biased, ohe_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_biased, Y_biased = pd.DataFrame(X_biased), pd.DataFrame(Y_biased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dbiased = xgb.DMatrix(X_biased, label=Y_biased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>579</th>\n",
       "      <th>580</th>\n",
       "      <th>581</th>\n",
       "      <th>582</th>\n",
       "      <th>583</th>\n",
       "      <th>584</th>\n",
       "      <th>585</th>\n",
       "      <th>586</th>\n",
       "      <th>587</th>\n",
       "      <th>588</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 589 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9   ...   579  580  581  582  \\\n",
       "0    0    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "1    0    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "2    0    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "3    0    0    0    0    0    1    0    0    0    0 ...     0    0    0    0   \n",
       "4    0    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "\n",
       "   583  584  585  586  587  588  \n",
       "0    0    0    0    0    0    0  \n",
       "1    0    0    0    0    0    0  \n",
       "2    0    0    0    0    0    0  \n",
       "3    0    0    0    0    0    0  \n",
       "4    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 589 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_biased.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, Y = generate_batch(df_pos, df_neg, 7000, ohe_labels=ohe_labels, pos_ratio=0.5)\n",
    "X_train_eq, Y_train_eq = pd.DataFrame(X), pd.DataFrame(Y)\n",
    "\n",
    "X, Y = generate_batch(df_pos, df_neg, 7000, ohe_labels=ohe_labels, pos_ratio=0.1)\n",
    "X_train_biased, Y_train_biased  = pd.DataFrame(X), pd.DataFrame(Y)\n",
    "\n",
    "X, Y = generate_batch(df_pos, df_neg, 3000, ohe_labels=ohe_labels, pos_ratio=0.1)\n",
    "X_test_biased, Y_test_biased  = pd.DataFrame(X), pd.DataFrame(Y)\n",
    "\n",
    "X, Y = generate_batch(df_pos, df_neg, 3000, ohe_labels=ohe_labels, pos_ratio=(df_test.c_cnt.sum())/(len(df_test.c_cnt)))\n",
    "X_test_same, Y_test_same  = pd.DataFrame(X), pd.DataFrame(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain_eq = xgb.DMatrix(X_train_eq, label=Y_train_eq)\n",
    "dtrain_biased = xgb.DMatrix(X_train_biased, label=Y_train_biased)\n",
    "dtest_biased = xgb.DMatrix(X_test_biased)\n",
    "dtest_same = xgb.DMatrix(X_test_same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=Y_train)\n",
    "dtest = xgb.DMatrix(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model: XGB model\n",
    "# dtest: dmatrix (if XGB native model) or DataFrame (if sklearn api model)\n",
    "# Y_test: Pandas Series of correct values\n",
    "def score_xgboost(model, dtest, Y_test):\n",
    "    prediction_thresh = 0.15 #np.round(model.predict(dtest)))\n",
    "    cm = confusion_matrix(Y_test, [1 if x >= prediction_thresh else 0 for x in model.predict(dtest)])\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    precision, recall = tp/(tp+fp), tp/(tp+fn)\n",
    "    print(cm)\n",
    "    print(\"Y positive ratio: \", float(Y_test.sum() / len(Y_test)))\n",
    "    print(\"Precision: \", precision)\n",
    "    print(\"Recall: \", recall)\n",
    "    print(\"logloss: \", log_loss(Y_test, model.predict(dtest)))\n",
    "    print(\"f1 score: \", get_f1_score(cm))\n",
    "    print(\"positive accuracy: \", tp/(tp + fn))\n",
    "    print(\"negative accuracy: \", tn/(tn + fp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# params = {'max_depth':6, 'eta':0.3, 'objective':'binary:logistic', \n",
    "#           'subsample':0.5, 'min_child_weight':3, 'gamma':5, \n",
    "#           'max_delta_step':2, 'eval_metric':'logloss'}\n",
    "# params = {'max_depth':6, 'eta':0.3, 'silent':1, 'objective':'binary:logistic',\n",
    "#           'subsample':0.5,'min_child_weight':3, 'gamma': 5, 'max_delta_step':2,\n",
    "#           'scale_pos_weight':(len(df_test.c_cnt) - df_test.c_cnt.sum())/(df_test.c_cnt.sum())}\n",
    "num_rounds = 200\n",
    "# params = {'max_depth':6, 'eta':0.3, 'silent':1, 'objective':'binary:logistic',\n",
    "#           'subsample':0.5,'min_child_weight':3, 'gamma': 5,\n",
    "#           'scale_pos_weight':10000}\n",
    "# num_rounds = 150\n",
    "params={'eta':0.2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[21325  8658]\n",
      " [    3    14]]\n",
      "Y positive ratio:  0.0005666666666666667\n",
      "Precision:  0.0016143911439114391\n",
      "Recall:  0.8235294117647058\n",
      "logloss:  1.118451977837207\n",
      "f1 score:  0.0032224651858671883\n"
     ]
    }
   ],
   "source": [
    "# # XGBboost batch training\n",
    "# X, Y = generate_batch(df_pos, df_neg, 1000, ohe_labels=ohe_labels)\n",
    "# X, Y = pd.DataFrame(X), pd.DataFrame(Y)\n",
    "# dmatrix = xgb.DMatrix(X, label=Y)\n",
    "# model = xgb.train(params, dmatrix, num_boost_round=num_rounds)\n",
    "# for i in range(num_rounds, 1000):\n",
    "#     print(\"iteration: \", i)\n",
    "#     X, Y = generate_batch(df_pos, df_neg, 100, ohe_labels=ohe_labels)\n",
    "#     X, Y = pd.DataFrame(X), pd.DataFrame(Y)\n",
    "#     dmatrix = xgb.DMatrix(X, label=Y)\n",
    "#     model.update(dmatrix, i)\n",
    "# score_xgboost(model, dtest, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_rounds = 50\n",
    "params = {'max_depth':5, 'eta':0.25, 'objective':'binary:logistic',\n",
    "          'subsample':0.1, 'max_delta_step':8, 'min_child_weight':20, 'gamma':20}\n",
    "params={'max_depth':5,'objective':'binary:logistic', 'eta':0.25, 'max_delta_step':8, 'min_child_weight':20, 'gamma':20}\n",
    "# params={'objective':'binary:logistic'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.train(params, dtrain, num_boost_round=num_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20086172 0.05809835 0.05400364 ... 0.20086172 0.09909448 0.06024683]\n",
      "[[25021  4959]\n",
      " [   12     8]]\n",
      "Y positive ratio:  0.0006666666666666666\n",
      "Precision:  0.0016106301590497283\n",
      "Recall:  0.4\n",
      "logloss:  0.09637816922596346\n",
      "f1 score:  0.003208341688389814\n",
      "positive accuracy:  0.4\n",
      "negative accuracy:  0.8345897264843228\n"
     ]
    }
   ],
   "source": [
    "# without counts\n",
    "print(model.predict(dtest))\n",
    "score_xgboost(model, dtest, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = [28728, 1253, 10, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive accuracy:  0.47368421052631576\n",
      "negative accuracy:  0.9582068643474201\n"
     ]
    }
   ],
   "source": [
    "print(\"positive accuracy: \", tp/(tp + fn))\n",
    "print(\"negative accuracy: \", tn/(tn + fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0641287  0.4207093  0.07158999 ... 0.0641287  0.7447072  0.0641287 ]\n",
      "[[28728  1253]\n",
      " [   10     9]]\n",
      "Y positive ratio:  0.0006333333333333333\n",
      "Precision:  0.0071315372424722665\n",
      "Recall:  0.47368421052631576\n",
      "logloss:  0.17648345293700696\n",
      "f1 score:  0.01405152224824356\n",
      "positive accuracy:  0.47368421052631576\n",
      "negative accuracy:  0.9582068643474201\n"
     ]
    }
   ],
   "source": [
    "#with counts\n",
    "print(model.predict(dtest))\n",
    "score_xgboost(model, dtest, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06502938 0.06502938 0.06502938 ... 0.06502938 0.06502938 0.06502938]\n",
      "[[20822   166]\n",
      " [   10     2]]\n",
      "Y positive ratio:  0.0005714285714285715\n",
      "Precision:  0.011904761904761904\n",
      "Recall:  0.16666666666666666\n",
      "logloss:  0.12425036974322229\n",
      "f1 score:  0.022222222222222223\n",
      "positive accuracy:  4.783315794508753e-05\n",
      "negative accuracy:  0.4979910073663063\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(dtest))\n",
    "score_xgboost(model, dtest, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19372  1616]\n",
      " [    7     5]]\n",
      "Y positive ratio:  0.0005714285714285715\n",
      "Precision:  0.0030845157310302285\n",
      "Recall:  0.4166666666666667\n",
      "logloss:  inf\n",
      "f1 score:  0.00612369871402327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1769: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n"
     ]
    }
   ],
   "source": [
    "score_xgboost(model, dtest, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18484  2504]\n",
      " [    7     5]]\n",
      "Y positive ratio:  0.0005714285714285715\n",
      "Precision:  0.0019928258270227183\n",
      "Recall:  0.4166666666666667\n",
      "logloss:  0.2539656011788895\n",
      "f1 score:  0.0039666798889329636\n"
     ]
    }
   ],
   "source": [
    "score_xgboost(model, dtest, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_eq = xgb.train(params, dtrain_eq, num_boost_round=num_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19590  1398]\n",
      " [    8     4]]\n",
      "Y positive ratio:  0.0005714285714285715\n",
      "Precision:  0.0028530670470756064\n",
      "Recall:  0.3333333333333333\n",
      "logloss:  0.1557951823147568\n",
      "f1 score:  0.005657708628005658\n"
     ]
    }
   ],
   "source": [
    "score_xgboost(xgb_eq, dtest, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_biased = xgb.train(params, dtrain_biased, num_boost_round=num_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17646  3342]\n",
      " [    7     5]]\n",
      "Y positive ratio:  0.0005714285714285715\n",
      "Precision:  0.0014938751120406335\n",
      "Recall:  0.4166666666666667\n",
      "logloss:  0.3924755790859816\n",
      "f1 score:  0.002977076510866329\n"
     ]
    }
   ],
   "source": [
    "score_xgboost(xgb_biased, dtest, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clf_eq = xgb.XGBClassifier().fit(X_train_eq, Y_train_eq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clf_biased = xgb.XGBClassifier().fit(X_train_biased, Y_train_biased)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hey, so I'll just summarize my results here. So firstly I sampled from the processed positives and negatives for my training set and used the combined day 1 for my test set. One huge problem I encountered is that I wasn't able to one hot encode the whole training or test set (or more than 100,000 rows) because the new one hot encoding function is really slow. Just looking at Activity Monitor, the memory the process consumes increases very slowly, whereas sklearn's categorical encoder is much faster. Maybe i didn't wait long enough, but i waited for about 20 min and there was less than a 2GB in memory consumption by python. So I think we should maybe switch back to the previous one, which uses sklearn's categorical encoder, to OHE and try to make some optimizations.\n",
    "\n",
    "For my datasets, I used the generate_batch to train on sets of 7,000 samples. I created balanced and biased datasets, where balanced has positive ratio of 0.5 and biased has positive ratio of 0.1. My test set was a batch of 3,000 samples from the combined_day1 with positive ratio equal to the empirical pos ratio of combined_day1. \n",
    "\n",
    "For XGBoost, I tried both the default XGBoost Booster model with the .train method, and tried the XGBClassifier model (which is an sklearn api). For both, I trained models on both the balanced and biased sets and then evaluated on the empirical set. Basically, the XGBClassifier is slow to train and not very good compared to the Booster model. The Booster model with default parameters gets about 2% precision and 100% recall (for both balanced and biased), so it's most likely overfitting. I read the docs and adjusted the parameters a bit, and the biased model (with positive ratio 10%) got 17% precision and 100% recall, and this was on only 10,000 samples. I think that on more samples and with more hyperparameter tuning it can be a lot better, since it still is likely overfitting. Even though it was only 17% precision, seems like a huge improvement over the previous model since I only changed like 2 hyperparameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB booster with equal pos/neg training set:\n",
      "Biased test set:\n",
      "[[2650   56]\n",
      " [  12  282]]\n",
      "Y positive ratio:  0.098\n",
      "Precision:  0.834319526627219\n",
      "Recall:  0.9591836734693877\n",
      "Empirical test set:\n",
      "[[2942   56]\n",
      " [   0    1]]\n",
      "Y positive ratio:  0.00033344448149383126\n",
      "Precision:  0.017543859649122806\n",
      "Recall:  1.0\n",
      "\n",
      "XGB booster with biased pos_ratio=0.1 training set:\n",
      "Biased test set:\n",
      "[[2691   15]\n",
      " [  22  272]]\n",
      "Y positive ratio:  0.098\n",
      "Precision:  0.9477351916376306\n",
      "Recall:  0.9251700680272109\n",
      "Empirical test set:\n",
      "[[2987   11]\n",
      " [   0    1]]\n",
      "Y positive ratio:  0.00033344448149383126\n",
      "Precision:  0.08333333333333333\n",
      "Recall:  1.0\n",
      "\n",
      "XGB Classifier with equal pos/neg training set:\n",
      "Biased test set:\n",
      "[[2598  108]\n",
      " [  17  277]]\n",
      "Y positive ratio:  0.098\n",
      "Precision:  0.7194805194805195\n",
      "Recall:  0.9421768707482994\n",
      "Empirical test set:\n",
      "[[2896  102]\n",
      " [   0    1]]\n",
      "Y positive ratio:  0.00033344448149383126\n",
      "Precision:  0.009708737864077669\n",
      "Recall:  1.0\n",
      "\n",
      "XGB Classifier with biased pos/neg training set:\n",
      "Biased test set:\n",
      "[[2649   57]\n",
      " [  37  257]]\n",
      "Y positive ratio:  0.098\n",
      "Precision:  0.8184713375796179\n",
      "Recall:  0.8741496598639455\n",
      "Empirical test set:\n",
      "[[2957   41]\n",
      " [   0    1]]\n",
      "Y positive ratio:  0.00033344448149383126\n",
      "Precision:  0.023809523809523808\n",
      "Recall:  1.0\n"
     ]
    }
   ],
   "source": [
    "# print(\"XGB booster with equal pos/neg training set:\")\n",
    "# print(\"Biased test set:\")\n",
    "# score_xgboost(xgb_eq, dtest_biased, Y_test_biased)\n",
    "# print(\"Empirical test set:\")\n",
    "# score_xgboost(xgb_eq, dtest_same, Y_test_same)\n",
    "# print()\n",
    "# print(\"XGB booster with biased pos_ratio=0.1 training set:\")\n",
    "# print(\"Biased test set:\")\n",
    "# score_xgboost(xgb_biased, dtest_biased, Y_test_biased)\n",
    "# print(\"Empirical test set:\")\n",
    "# score_xgboost(xgb_biased, dtest_same, Y_test_same)\n",
    "# print()\n",
    "# print(\"XGB Classifier with equal pos/neg training set:\")\n",
    "# print(\"Biased test set:\")\n",
    "# score_xgboost(clf_eq, X_test_biased, Y_test_biased)\n",
    "# print(\"Empirical test set:\")\n",
    "# score_xgboost(clf_eq, X_test_same, Y_test_same)\n",
    "# print()\n",
    "# print(\"XGB Classifier with biased pos/neg training set:\")\n",
    "# print(\"Biased test set:\")\n",
    "# score_xgboost(clf_biased, X_test_biased, Y_test_biased)\n",
    "# print(\"Empirical test set:\")\n",
    "# score_xgboost(clf_biased, X_test_same, Y_test_same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a4d7dd780>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApcAAAETCAYAAABjpS3CAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a4d7ddfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_importance(xgb_eq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_importance(xgb_biased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_importance(clf_eq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_importance(clf_biased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(penalty='l2', C=0.1, solver='newton-cg', multi_class='ovr', max_iter=500)\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-119-b00b1abc1053>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'l2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'newton-cg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ovr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrain_cm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_cm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1290\u001b[0m                       \u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m                       sample_weight=sample_weight)\n\u001b[0;32m-> 1292\u001b[0;31m             for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n\u001b[0m\u001b[1;32m   1293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m         \u001b[0mfold_coefs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfold_coefs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mlogistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight)\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             w0, n_iter_i = newton_cg(hess, func, grad, w0, args=args,\n\u001b[0;32m--> 719\u001b[0;31m                                      maxiter=max_iter, tol=tol)\n\u001b[0m\u001b[1;32m    720\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'liblinear'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m             coef_, intercept_, n_iter_i, = _fit_liblinear(\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/sklearn/utils/optimize.py\u001b[0m in \u001b[0;36mnewton_cg\u001b[0;34m(grad_hess, func, grad, x0, args, tol, maxiter, maxinner, line_search, warn)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;31m# Compute a search direction pk by applying the CG method to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;31m#  del2 f(xk) p = - fgrad f(xk) starting from 0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mfgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfhess_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_hess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mabsgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36m_logistic_grad_hess\u001b[0;34m(w, X, y, alpha, sample_weight)\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;31m# Calculate the double derivative with respect to intercept\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;31m# In the case of sparse matrices this returns a matrix object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0mdd_intercept\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mHs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_prod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_cm = confusion_matrix(y_train, lr.predict(X_train))\n",
    "train_precision, train_recall = cm_score(train_cm)\n",
    "print(train_cm)\n",
    "print(train_precision)\n",
    "print(train_recall)\n",
    "\n",
    "test_cm = confusion_matrix(y_test, lr.predict(X_test))\n",
    "test_precision, test_recall = cm_score(test_cm)\n",
    "print(test_cm)\n",
    "print(test_precision)\n",
    "print(test_recall)\n",
    "\n",
    "# print(get_f1_score(test_cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from sklearn.preprocessing import CategoricalEncoder\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the original data and transform it into xgb readable files - sparse array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reads a weird json, and returns the bids dataframe and ads dataframe\n",
    "def read_weird_json(path):\n",
    "    bids = []\n",
    "    ads = []\n",
    "\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            line_dict = json.loads(line.encode('utf-8'))\n",
    "            if 'advertiser_id' in line_dict:\n",
    "                if line_dict['rate_metric'] != 'CPC':\n",
    "                    continue\n",
    "                ads.append(line_dict)\n",
    "            else:\n",
    "                bids.append(line_dict)\n",
    "    df_bids = pd.DataFrame.from_records(bids)\n",
    "    df_ads = pd.DataFrame.from_records(ads)  \n",
    "    \n",
    "    return [df_bids, df_ads]\n",
    "\n",
    "#Returns a list of dataframes. Only looks at ads. \n",
    "def read_many_jsons(paths): \n",
    "    dfs = []\n",
    "    for path in paths: \n",
    "        dfs += [read_weird_json(path)[1]]\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfs = read_many_jsons(['./data/01-09-00001', './data/01-09-00003'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create one dataframe with the combined data. \n",
    "df = pd.concat(dfs)\n",
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Turns a timestamp into which minute the time was at - used as a categorical feature.\n",
    "def timestamp_to_min(timestamp, is_hour=True):\n",
    "    if is_hour:\n",
    "        return timestamp.split(':')[0][-2:]\n",
    "    else: \n",
    "        return timestamp.split(':')[1]\n",
    "\n",
    "#plots frequency of a feature's different classes, useful for exploratory analysis\n",
    "def plot_freq(col_name, df):\n",
    "    df_frequency = df.groupby(col_name).agg('count').sort_values('ad_type',ascending=False)\n",
    "    plt.plot([i for i in range(len(df_frequency.values))], [np.log(i[2]) for i in df_frequency.values])\n",
    "    plt.show()\n",
    "\n",
    "#if a feature only has one unique value, it tells us nothing, so we drop it.\n",
    "def remove_only_ones(df):\n",
    "    for col in df.columns:\n",
    "        if len(df[col].unique()) == 1:\n",
    "            df.drop(col, inplace=True,axis=1)\n",
    "\n",
    "#just prints how many unique values are in each feature\n",
    "def print_column_counts(df):    \n",
    "    for i in df:\n",
    "        print(i, df[i].nunique())\n",
    "\n",
    "#We do some final cleaning, changing all non-numerical features into strings for later.\n",
    "def preprocess(df):    \n",
    "    for i in df:\n",
    "        if i[-1] != 't' or i[-2] != 'n' or i[-3] != 'c':\n",
    "            df[i] = df[i].astype('str')\n",
    "    remove_only_ones(df)\n",
    "    if 'site_id' in df.columns:\n",
    "        df.drop('site_id',inplace=True,axis=1)\n",
    "    \n",
    "#given a categorical column, we apply our earlier strategy of one-hot-encoding with maximum thresh=200\n",
    "def transform_column(df, col, thresh=10, return_labels=False):\n",
    "    df_frequency = df[[col, 'c_cnt']].groupby(col).agg('count').sort_values('c_cnt',ascending=False)\n",
    "    if df[col].nunique() > thresh:\n",
    "        enc = CategoricalEncoder(categories=[sorted(df_frequency[0:thresh].index.values)],handle_unknown='ignore')\n",
    "        labels = df_frequency[0:thresh].index.values\n",
    "    else:\n",
    "        enc = CategoricalEncoder(categories=[sorted(df_frequency.index.values)],handle_unknown='ignore')\n",
    "        labels = df_frequency.index.values\n",
    "    labels = [str(col) + str(i) for i in labels]\n",
    "    if return_labels:\n",
    "        return labels\n",
    "    enc.fit(df[col].values.reshape(-1, 1))\n",
    "    return enc.transform(df[col].values.reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#final preprocessing\n",
    "preprocess(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cutoff = int(np.floor(len(df) * 0.7))\n",
    "# print \"Total data: \", len(df), \" Cutoff: \", cutoff\n",
    "# train_df = df.iloc[:cutoff, :]\n",
    "# test_df = df.iloc[cutoff:, :]\n",
    "# print train_df.shape\n",
    "# print test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this set contains our numerical column names\n",
    "numerical_features = set(['c_cnt', 'c_flag_cnt', 'i_cnt', 'i_flag_cnt', 'r_cnt', 'vi_cnt', 'vi_flag_cnt', 'vv_cnt', 'vv_vvi_cnt'])\n",
    "\n",
    "#we create a copy so that X will not include 'c_cnt'\n",
    "df2 = df.copy()\n",
    "df2.drop('c_cnt',inplace=True,axis=1)\n",
    "X = np.hstack([transform_column(df, col) if col not in numerical_features else df[col].values.reshape(-1,1)\n",
    "               for col in df2])\n",
    "Y_true = df['c_cnt'].values[cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X[:cutoff, :]\n",
    "X_test = X[cutoff:, :]\n",
    "train_df = df.iloc[:cutoff, :]\n",
    "test_df = df.iloc[cutoff:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=train_df['c_cnt'])\n",
    "dtest = xgb.DMatrix(X_test, label=test_df['c_cnt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param = {'max_depth':1, 'eta':1, 'silent':1, 'objective':'binary:logistic' }\n",
    "num_round = 2\n",
    "bst = xgb.train(param, dtrain, num_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = bst.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0\n"
     ]
    }
   ],
   "source": [
    "print(sum(np.round(preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0\n"
     ]
    }
   ],
   "source": [
    "print(sum(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8595,    0],\n",
       "       [   0,    6]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(Y_true, np.round(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
